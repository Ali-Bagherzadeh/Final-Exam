{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ali-Bagherzadeh/Final-Exam/blob/main/Final_Exam_Assignment_ab4_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW7B2sBYIrZM"
      },
      "source": [
        "# Ali Bagherzadeh final Exam Assignment (40 points - Total of 45 is Possible)\n",
        "## Due December 7, 2022, @ 8:00 ampip install keras\n",
        "Note that there will be no extensions given for this assignment as there is a tight timeline for grading. \n",
        "\n",
        "For this assignment, I have provided each of you with your own training dataset. Your goal is to train a deep neural network to uncover the code image provided to you. \n",
        "\n",
        "I will provide you with instructions throughout. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErRaysoSIrZU"
      },
      "outputs": [],
      "source": [
        "# Add your import statements here\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numpy import load\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.special import expit as activation_function\n",
        "from scipy.stats import truncnorm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np18kvkWIrZV",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# This is a tool I have provided you to help you download your file.\n",
        "\n",
        "def download_file(url, filename):\n",
        "    \"\"\"\n",
        "    A function that downloads the data file from a URL\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : string\n",
        "        url where the file to download is located\n",
        "    filename : string\n",
        "        location where to save the file\n",
        "    reporthook : function\n",
        "        callback to display the download progress\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(filename):\n",
        "        urllib.request.urlretrieve(url, filename, reporthook)\n",
        "        \n",
        "def reporthook(count, block_size, total_size):\n",
        "    \"\"\"\n",
        "    A function that displays the status and speed of the download\n",
        "    \"\"\"\n",
        "\n",
        "    global start_time\n",
        "    if count == 0:\n",
        "        start_time = time.time()\n",
        "        return\n",
        "    duration = time.time() - start_time\n",
        "    progress_size = int(count * block_size)\n",
        "    speed = int(progress_size / (1024 * duration + 0.0001))\n",
        "    percent = int(count * block_size * 100 / total_size)\n",
        "    sys.stdout.write(\"\\r...%d%%, %d MB, %d KB/s, %d seconds passed\" %\n",
        "                     (percent, progress_size / (1024 * 1024), speed, duration))\n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uzdqq6G_IrZW",
        "tags": [
          "skip-execution"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb04a35-1a5a-479a-fe12-3a4f51fde451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...100%, 24 MB, 3248 KB/s, 7 seconds passed"
          ]
        }
      ],
      "source": [
        "# You can download your file by typing your first name into the name block\n",
        "# The name used is the first part of your first name as listed in BB learn\n",
        "# If you have problems downloading the data please reach out to me\n",
        "\n",
        "name = 'Ali'\n",
        "download_file(f'https://zenodo.org/record/7339649/files/data_{name}.npz?download=1','data.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF0AtlDMIrZX"
      },
      "source": [
        "## Loading the Data (3 points)\n",
        "The data is provided to you as a compressed NumPy array saved as 'data.npz'. When working with real data you might need to figure out how data is stored. Use the information on 'npz' files to figure out what data you have. The data file contains three NumPy arrays. \n",
        "1. The features for the training dataset\n",
        "2. The regression values for the training dataset\n",
        "3. The validation features that contain your code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nItcM_sEUsSo",
        "outputId": "20ed1803-7c4a-4364-8bdf-795185093633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r95oWV6IrZZ",
        "outputId": "a425ae6e-8c7e-4d79-c510-0918d4e220bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_feat\n",
            "[[50.15881786  0.14740836 47.24435191 ... 19.23321463 21.46233564\n",
            "   0.65416514]\n",
            " [76.35249032  1.83990513 22.14138396 ... 20.50781737 43.76897403\n",
            "  45.89079564]\n",
            " [47.16151439  0.11889541 36.88076261 ... 30.8507654  45.18006429\n",
            "  73.74330105]\n",
            " ...\n",
            " [62.39784079  1.52349286 39.20841027 ... 13.18610795 78.0266964\n",
            "  51.64192514]\n",
            " [28.85380729  0.14590989 25.24930434 ...  6.59723584 79.35698998\n",
            "  48.00198864]\n",
            " [41.18016932  1.1209152  23.94349425 ...  1.82253516 28.29859169\n",
            "  58.92101681]]\n",
            "training_true\n",
            "[[0.79256891 0.37791841 0.35093268]\n",
            " [0.31450257 0.37992679 0.26829553]\n",
            " [0.31390719 0.60961793 0.58662354]\n",
            " ...\n",
            " [0.20300577 0.38135618 0.69663442]\n",
            " [0.38321709 0.28029869 0.64965628]\n",
            " [0.61621451 0.30044216 0.67955223]]\n",
            "validation_feat\n",
            "[[17.55877886  4.35091121 23.74038128 ... 14.97936909 23.89848764\n",
            "  63.04844499]\n",
            " [17.55877886  4.35091121 23.74038128 ... 14.97936909 23.89848764\n",
            "  63.04844499]\n",
            " [17.55877886  4.35091121 23.74038128 ... 14.97936909 23.89848764\n",
            "  63.04844499]\n",
            " ...\n",
            " [17.55877886  4.35091121 23.74038128 ... 14.97936909 23.89848764\n",
            "  63.04844499]\n",
            " [17.55877886  4.35091121 23.74038128 ... 14.97936909 23.89848764\n",
            "  63.04844499]\n",
            " [17.55877886  4.35091121 23.74038128 ... 14.97936909 23.89848764\n",
            "  63.04844499]]\n"
          ]
        }
      ],
      "source": [
        "# Your Code goes here\n",
        "dataAli = np.load('/content/gdrive/MyDrive/AliMl/data_Ali.npz')\n",
        "lst = dataAli.files\n",
        "for item in lst:\n",
        "    print(item)\n",
        "    print(dataAli[item])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTkE_5Wuecw0",
        "outputId": "c4b82ab5-87fd-4ef8-d8de-893005b9b2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_feat shape is: (100000, 30)\n",
            "training_true shape is: (100000, 3)\n",
            "validation_feat shape is: (65536, 30)\n"
          ]
        }
      ],
      "source": [
        "print('training_feat shape is:', dataAli['training_feat'].shape)\n",
        "print('training_true shape is:',dataAli['training_true'].shape)\n",
        "print('validation_feat shape is:',dataAli['validation_feat'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmYRK_qcfA4H"
      },
      "outputs": [],
      "source": [
        "training_feat = dataAli['training_feat']\n",
        "training_true = dataAli['training_true']\n",
        "validation_feat = dataAli['validation_feat']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8-Mm0COIrZb"
      },
      "source": [
        "## Preprocessing the Data (5 points)\n",
        "\n",
        "You should explore the data and figure out the best way to preprocess the data. \n",
        "\n",
        "Hints: \n",
        "1. For the regression values, these at the end will represent colors in RGB space from [0,1]. It is recommended to use a max-min scalar between 0 and 1. \n",
        "2. For the training features, you should look at the data and determine the best scaling method. Look at our class notes for a reminder of what other scaler might be useful. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5URkRLmaIrZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee7fe4b-e2bb-450d-f56a-4939e91a731f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum training_feat: 0.000\n",
            "maximum training_feat:94.941\n",
            "mean training_feat:25.740\n",
            "median training_feat:19.659\n",
            "std training_feat:21.234\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here\n",
        "# Calculate and print minimum, maximum, mean, median and std values\n",
        "print(\"minimum training_feat: %.3f\" % np.min(training_feat))\n",
        "print(\"maximum training_feat:%.3f\" % np.max(training_feat))\n",
        "print(\"mean training_feat:%.3f\" % training_feat.mean())\n",
        "print(\"median training_feat:%.3f\" % np.median(training_feat))\n",
        "print(\"std training_feat:%.3f\" % np.std(training_feat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GIxhX3hIrZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96944ea-9f07-41a1-de07-9ab771023e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum training_true:0.000\n",
            "maximum training_true:1.000\n",
            "mean training_true:0.492\n",
            "median training_true:0.491\n",
            "std training_true:0.159\n"
          ]
        }
      ],
      "source": [
        "print(\"minimum training_true:%.3f\" % np.min(training_true))\n",
        "print(\"maximum training_true:%.3f\" % np.max(training_true))\n",
        "print(\"mean training_true:%.3f\" % training_true.mean())\n",
        "print(\"median training_true:%.3f\" % np.median(training_true))\n",
        "print(\"std training_true:%.3f\" % np.std(training_true))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAczNsjTrsxA"
      },
      "outputs": [],
      "source": [
        "y_scaler = MinMaxScaler()\n",
        "scaled_training_true = y_scaler.fit_transform(training_true)\n",
        "x_scaler = StandardScaler()\n",
        "scaled_training_feat = x_scaler.fit_transform(training_feat)\n",
        "scaled_validation_feat = x_scaler.transform(validation_feat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-_zmBy_IrZf"
      },
      "source": [
        "## Building the Dataset (5 points)\n",
        "\n",
        "When training neural networks it is important to build a dataset that allows the machinery to sample the data. This also can be used to conduct some preprocessing of the data to make it work with PyTorch. \n",
        "\n",
        "I have provided you with the framework for a Dataset Class. \n",
        "\n",
        "You should:\n",
        "1. Convert the x and y data to a tensor 'float32' and put it on the GPU.\n",
        "2. Save the len of the data\n",
        "3. Add the code so when `__getitem__` is called it returns the x and y values\n",
        "3. make it so `__len__` returns the lenght when calle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fATZjUAnIrZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adebb3c5-51ad-44a6-a5f3-26e55e8aaaed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lIOiSIOYKh8"
      },
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "  '''Dataset Class to store the samples and their corresponding labels, \n",
        "  and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, X: np.ndarray, y: np.ndarray, device = 'cuda') -> None:\n",
        "\n",
        "    # need to convert float64 to float32 else \n",
        "    # will get the following error\n",
        "    # RuntimeError: expected scalar type Double but found Float\n",
        "    self.X = torch.from_numpy(X.astype(np.float32)).to(device)\n",
        "    self.y = torch.from_numpy(y.astype(np.float32)).to(device)\n",
        "    self.len = self.X.shape[0]\n",
        "  \n",
        "  def __getitem__(self, index: int) -> tuple:\n",
        "    return self.X[index], self.y[index]\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return self.len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52XEDY9pIrZh"
      },
      "source": [
        "## Train-test Split (3 points)\n",
        "\n",
        "1. You should conduct a train-test split of the training data so you can make sure that your model does not overfit the data. A good ratio is 66/33 train \n",
        "2. You should instantiate the training dataset using the data class implemented above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbSvvFlA45Oc"
      },
      "outputs": [],
      "source": [
        "dataclass = Data(scaled_training_feat, scaled_training_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IaXyzv3aPxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ff8fbe-b72a-4f13-eddd-d477622d6a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.4874, -0.7037, -0.4346, -1.5573, -0.8812, -1.3585, -1.4127, -0.0666,\n",
            "         0.5727,  0.2660,  1.4100, -0.2015, -0.8363, -0.9285,  1.1009, -1.1602,\n",
            "         0.7519, -0.1965, -0.8376,  1.6895, -1.1739,  0.9670,  0.3658, -1.2774,\n",
            "         1.0545,  0.8572, -1.7039,  0.2780, -0.0160,  0.1212], device='cuda:0') tensor([0.3145, 0.3799, 0.2683], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# data visualization after class transformation for first element\n",
        "features1, labels1 = dataclass[1]\n",
        "print(features1, labels1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1qQ1MjQIrZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00dde92f-3dda-43fa-c511-a321cfd71158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test size X and y: 30000 , 30000\n",
            "Train size X and y: 70000 , 70000\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here\n",
        "X_train,X_test,y_train,y_test=train_test_split(dataclass.X, dataclass.y,test_size=0.3,random_state=3)\n",
        "print(f'Test size X and y: {len(X_test)} , {len(y_test)}')\n",
        "print(f'Train size X and y: {len(X_train)} , {len(y_train)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5ebhasXIrZh"
      },
      "source": [
        "## Build the Dataloader (3 points)\n",
        "\n",
        "Pytorch uses DataLoaders to efficiently sample from a training dataset. Instantiate a Pytorch DataLoader using the dataset. \n",
        "\n",
        "You should set the following parameters:\n",
        "1. Batch size = 64\n",
        "2. Shuffle = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XHWPj3vALSh"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader_X = DataLoader(X_train, batch_size=batch_size, shuffle=True)\n",
        "train_dataloader_y = DataLoader(y_train, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader_X = DataLoader(X_test, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader_y = DataLoader(y_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train_dataloader_X and train_dataloader_y: {len(train_dataloader_X)} , {len(train_dataloader_y)}')\n",
        "print(f'test_dataloader_X and test_dataloader_y: {len(test_dataloader_X)} , {len(test_dataloader_y)}')"
      ],
      "metadata": {
        "id": "IPLtxDC1MCC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eaa4115-d021-48d4-ea7b-cc1e3507a79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataloader_X and train_dataloader_y: 1094 , 1094\n",
            "test_dataloader_X and test_dataloader_y: 469 , 469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader_X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_34Fu75N2ip",
        "outputId": "a686e817-d0c3-4c36-b58b-85c87d4dda6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7384, -0.6274,  0.9602,  ...,  0.7857,  0.0905, -1.4873],\n",
              "        [-1.0121, -0.4975,  1.3440,  ..., -0.5553,  0.0862,  1.2823],\n",
              "        [ 1.2869, -0.4691, -1.5108,  ...,  0.3584,  1.5616, -1.0055],\n",
              "        ...,\n",
              "        [ 1.4791, -0.9520, -1.5834,  ...,  0.9941, -1.4693,  0.0837],\n",
              "        [ 1.3195, -0.0480, -0.5547,  ..., -0.0141,  1.0717,  0.4967],\n",
              "        [-1.0702,  1.5034,  0.9880,  ...,  1.3588,  1.6577, -1.1785]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WyuuQgLIrZi"
      },
      "source": [
        "## Building a Neural Network (5 points)\n",
        "\n",
        "Using the provided class framework which inherits the `nn.Module` type in PyTorch builds a 4-layer neural network to complete the multiple regression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Neural_Network(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
        "        super(Neural_Network, self).__init__()\n",
        "        # in this part you should intantiate each of the layer components\n",
        "        self.fc1 = nn.Linear(30, 30)\n",
        "        self.fc2 = nn.Linear(30, 30)\n",
        "        self.fc3 = nn.Linear(30, 10)\n",
        "        self.fc4 = nn.Linear(10, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "        #return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "HRYtLPwEYzcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysm3wNMGIrZi"
      },
      "source": [
        "## Instantiate the Model (3 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye4eD8FrIrZi",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# number of features (len of X cols)\n",
        "input_dim = len(train_dataloader_X)\n",
        "# number of hidden layers set this to 50\n",
        "hidden_layers = 50\n",
        "# Add the number of output dimensions\n",
        "output_dim = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate the regression model\n",
        "# make sure to put it on your GPU\n",
        "model = Neural_Network(input_dim, hidden_layers, output_dim).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUv-ttPXZiOL",
        "outputId": "19c19e91-0f72-4482-d74f-69ba98fefb8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural_Network(\n",
            "  (fc1): Linear(in_features=30, out_features=30, bias=True)\n",
            "  (fc2): Linear(in_features=30, out_features=30, bias=True)\n",
            "  (fc3): Linear(in_features=30, out_features=10, bias=True)\n",
            "  (fc4): Linear(in_features=10, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNQLQ6LFIrZi",
        "tags": [
          "skip-execution"
        ]
      },
      "outputs": [],
      "source": [
        "# criterion to computes the loss between input and target\n",
        "# Choose a good criteria\n",
        "# Initialize the loss function\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# optimizer that will be used to update weights and biases\n",
        "# you can choose any optimizer. I would recommend ADAM.\n",
        "# This problem should not be hard to optimize. A good starting learning rate is 3e-5. \n",
        "learning_rate = 3e-5\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhRn81H1QHo6"
      },
      "outputs": [],
      "source": [
        "# https://courses.coe.drexel.edu/MEM/MEMT680/Topic_10/7_optimization_tutorial.html?highlight=adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdvKzZaHIrZj"
      },
      "source": [
        "## Train the Model (5 points)\n",
        "\n",
        "Training the model is conducted in a number of steps using loops.\n",
        "\n",
        "1. Set up a loop for each epoch\n",
        "2. Set a parameter to save the running loss\n",
        "3. Set up a nested loop that goes through the batches from the DataLoader you built\n",
        "    - I would recommend using enumerate to include the counts in the loop\n",
        "    - The dataloader will return a tuple that is the inputs and the labels\n",
        "4. Conduct the forward propagation of the model\n",
        "    - Give the model the inputs and compute the outputs\n",
        "    - Compute the loss given the criteria. \n",
        "5. Use the zero gradient method to remove the gradients from the optimizer\n",
        "6. Use the backward method to compute the gradients\n",
        "7. Use the step method in the optimizer to take an optimization step\n",
        "8. Compute the running loss by calling the item method and adding it to the running loss for each minibatch\n",
        "9. For each epoch print the epoch and the loss\n",
        "\n",
        "Note: If you find this challenging I would recommend that you look at examples of other pytorch training loops online. This is a very standard workflow. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, TensorDataset\n",
        "\n",
        "tensor_Xp_train = torch.stack([torch.Tensor(el) for el in X_train])\n",
        "tensor_yp_train = torch.stack([torch.Tensor(el) for el in y_train])\n",
        "dataset_p_train = TensorDataset(tensor_Xp_train, tensor_yp_train)\n",
        "loader_p_train = DataLoader(dataset_p_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "tensor_Xp_test = torch.stack([torch.Tensor(el) for el in X_test])\n",
        "tensor_yp_test = torch.stack([torch.Tensor(el) for el in y_test])\n",
        "dataset_p_test = TensorDataset(tensor_Xp_test, tensor_yp_test)\n",
        "loader_p_test = DataLoader(dataset_p_test, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "UMnbZLuXWEgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "\n",
        "# sets the number of epochs to train 20 should be sufficent.\n",
        "# This should take about 5-10 minutes to train.\n",
        "\n",
        "# Your code should go here\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "FkZhhnnFXoGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(loader_p_train, model, loss_fn, optimizer)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYwskQK7XoKl",
        "outputId": "08697f01-9921-4613-8b9b-f40c1359b145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.362271  [    0/70000]\n",
            "loss: 0.325181  [ 6400/70000]\n",
            "loss: 0.285085  [12800/70000]\n",
            "loss: 0.249203  [19200/70000]\n",
            "loss: 0.222825  [25600/70000]\n",
            "loss: 0.181805  [32000/70000]\n",
            "loss: 0.164308  [38400/70000]\n",
            "loss: 0.134513  [44800/70000]\n",
            "loss: 0.107801  [51200/70000]\n",
            "loss: 0.088113  [57600/70000]\n",
            "loss: 0.078435  [64000/70000]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.045102  [    0/70000]\n",
            "loss: 0.056662  [ 6400/70000]\n",
            "loss: 0.036779  [12800/70000]\n",
            "loss: 0.028278  [19200/70000]\n",
            "loss: 0.032274  [25600/70000]\n",
            "loss: 0.029257  [32000/70000]\n",
            "loss: 0.034232  [38400/70000]\n",
            "loss: 0.023014  [44800/70000]\n",
            "loss: 0.023902  [51200/70000]\n",
            "loss: 0.019381  [57600/70000]\n",
            "loss: 0.020263  [64000/70000]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.019835  [    0/70000]\n",
            "loss: 0.024893  [ 6400/70000]\n",
            "loss: 0.020631  [12800/70000]\n",
            "loss: 0.021068  [19200/70000]\n",
            "loss: 0.022485  [25600/70000]\n",
            "loss: 0.017652  [32000/70000]\n",
            "loss: 0.017531  [38400/70000]\n",
            "loss: 0.023014  [44800/70000]\n",
            "loss: 0.016797  [51200/70000]\n",
            "loss: 0.016369  [57600/70000]\n",
            "loss: 0.016916  [64000/70000]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.016981  [    0/70000]\n",
            "loss: 0.014902  [ 6400/70000]\n",
            "loss: 0.014147  [12800/70000]\n",
            "loss: 0.014502  [19200/70000]\n",
            "loss: 0.018117  [25600/70000]\n",
            "loss: 0.016550  [32000/70000]\n",
            "loss: 0.020194  [38400/70000]\n",
            "loss: 0.016551  [44800/70000]\n",
            "loss: 0.013907  [51200/70000]\n",
            "loss: 0.012733  [57600/70000]\n",
            "loss: 0.014959  [64000/70000]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.013014  [    0/70000]\n",
            "loss: 0.012596  [ 6400/70000]\n",
            "loss: 0.015168  [12800/70000]\n",
            "loss: 0.015539  [19200/70000]\n",
            "loss: 0.014959  [25600/70000]\n",
            "loss: 0.012524  [32000/70000]\n",
            "loss: 0.012841  [38400/70000]\n",
            "loss: 0.013199  [44800/70000]\n",
            "loss: 0.013165  [51200/70000]\n",
            "loss: 0.014245  [57600/70000]\n",
            "loss: 0.012794  [64000/70000]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.009771  [    0/70000]\n",
            "loss: 0.012138  [ 6400/70000]\n",
            "loss: 0.011890  [12800/70000]\n",
            "loss: 0.009910  [19200/70000]\n",
            "loss: 0.011153  [25600/70000]\n",
            "loss: 0.012287  [32000/70000]\n",
            "loss: 0.010983  [38400/70000]\n",
            "loss: 0.012373  [44800/70000]\n",
            "loss: 0.010320  [51200/70000]\n",
            "loss: 0.009858  [57600/70000]\n",
            "loss: 0.009791  [64000/70000]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.014063  [    0/70000]\n",
            "loss: 0.008904  [ 6400/70000]\n",
            "loss: 0.009194  [12800/70000]\n",
            "loss: 0.011978  [19200/70000]\n",
            "loss: 0.009596  [25600/70000]\n",
            "loss: 0.009418  [32000/70000]\n",
            "loss: 0.009911  [38400/70000]\n",
            "loss: 0.011599  [44800/70000]\n",
            "loss: 0.010735  [51200/70000]\n",
            "loss: 0.009638  [57600/70000]\n",
            "loss: 0.009558  [64000/70000]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.008574  [    0/70000]\n",
            "loss: 0.009554  [ 6400/70000]\n",
            "loss: 0.010034  [12800/70000]\n",
            "loss: 0.010574  [19200/70000]\n",
            "loss: 0.011893  [25600/70000]\n",
            "loss: 0.010720  [32000/70000]\n",
            "loss: 0.009870  [38400/70000]\n",
            "loss: 0.007356  [44800/70000]\n",
            "loss: 0.008457  [51200/70000]\n",
            "loss: 0.010000  [57600/70000]\n",
            "loss: 0.008475  [64000/70000]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.009191  [    0/70000]\n",
            "loss: 0.010045  [ 6400/70000]\n",
            "loss: 0.009891  [12800/70000]\n",
            "loss: 0.010022  [19200/70000]\n",
            "loss: 0.008220  [25600/70000]\n",
            "loss: 0.011478  [32000/70000]\n",
            "loss: 0.008005  [38400/70000]\n",
            "loss: 0.009767  [44800/70000]\n",
            "loss: 0.010281  [51200/70000]\n",
            "loss: 0.007755  [57600/70000]\n",
            "loss: 0.008423  [64000/70000]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.010050  [    0/70000]\n",
            "loss: 0.008847  [ 6400/70000]\n",
            "loss: 0.009601  [12800/70000]\n",
            "loss: 0.008535  [19200/70000]\n",
            "loss: 0.007782  [25600/70000]\n",
            "loss: 0.007935  [32000/70000]\n",
            "loss: 0.008957  [38400/70000]\n",
            "loss: 0.008329  [44800/70000]\n",
            "loss: 0.007170  [51200/70000]\n",
            "loss: 0.007676  [57600/70000]\n",
            "loss: 0.007966  [64000/70000]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.008186  [    0/70000]\n",
            "loss: 0.009052  [ 6400/70000]\n",
            "loss: 0.007270  [12800/70000]\n",
            "loss: 0.008964  [19200/70000]\n",
            "loss: 0.009454  [25600/70000]\n",
            "loss: 0.007301  [32000/70000]\n",
            "loss: 0.008628  [38400/70000]\n",
            "loss: 0.006823  [44800/70000]\n",
            "loss: 0.008068  [51200/70000]\n",
            "loss: 0.007721  [57600/70000]\n",
            "loss: 0.006294  [64000/70000]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.008462  [    0/70000]\n",
            "loss: 0.007823  [ 6400/70000]\n",
            "loss: 0.007884  [12800/70000]\n",
            "loss: 0.007631  [19200/70000]\n",
            "loss: 0.009578  [25600/70000]\n",
            "loss: 0.007398  [32000/70000]\n",
            "loss: 0.006734  [38400/70000]\n",
            "loss: 0.007245  [44800/70000]\n",
            "loss: 0.007748  [51200/70000]\n",
            "loss: 0.007840  [57600/70000]\n",
            "loss: 0.007395  [64000/70000]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.007235  [    0/70000]\n",
            "loss: 0.008977  [ 6400/70000]\n",
            "loss: 0.006891  [12800/70000]\n",
            "loss: 0.007446  [19200/70000]\n",
            "loss: 0.008040  [25600/70000]\n",
            "loss: 0.006866  [32000/70000]\n",
            "loss: 0.008089  [38400/70000]\n",
            "loss: 0.006095  [44800/70000]\n",
            "loss: 0.008041  [51200/70000]\n",
            "loss: 0.006780  [57600/70000]\n",
            "loss: 0.006831  [64000/70000]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.008495  [    0/70000]\n",
            "loss: 0.006771  [ 6400/70000]\n",
            "loss: 0.006350  [12800/70000]\n",
            "loss: 0.007812  [19200/70000]\n",
            "loss: 0.006949  [25600/70000]\n",
            "loss: 0.006069  [32000/70000]\n",
            "loss: 0.006458  [38400/70000]\n",
            "loss: 0.008998  [44800/70000]\n",
            "loss: 0.007363  [51200/70000]\n",
            "loss: 0.008255  [57600/70000]\n",
            "loss: 0.008576  [64000/70000]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.008148  [    0/70000]\n",
            "loss: 0.007747  [ 6400/70000]\n",
            "loss: 0.007006  [12800/70000]\n",
            "loss: 0.005951  [19200/70000]\n",
            "loss: 0.006136  [25600/70000]\n",
            "loss: 0.008505  [32000/70000]\n",
            "loss: 0.006730  [38400/70000]\n",
            "loss: 0.006870  [44800/70000]\n",
            "loss: 0.006500  [51200/70000]\n",
            "loss: 0.007213  [57600/70000]\n",
            "loss: 0.006991  [64000/70000]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.007465  [    0/70000]\n",
            "loss: 0.006213  [ 6400/70000]\n",
            "loss: 0.006114  [12800/70000]\n",
            "loss: 0.006963  [19200/70000]\n",
            "loss: 0.006358  [25600/70000]\n",
            "loss: 0.006354  [32000/70000]\n",
            "loss: 0.005348  [38400/70000]\n",
            "loss: 0.006015  [44800/70000]\n",
            "loss: 0.007429  [51200/70000]\n",
            "loss: 0.005919  [57600/70000]\n",
            "loss: 0.007267  [64000/70000]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.006929  [    0/70000]\n",
            "loss: 0.005267  [ 6400/70000]\n",
            "loss: 0.006436  [12800/70000]\n",
            "loss: 0.006289  [19200/70000]\n",
            "loss: 0.007654  [25600/70000]\n",
            "loss: 0.006436  [32000/70000]\n",
            "loss: 0.007503  [38400/70000]\n",
            "loss: 0.005464  [44800/70000]\n",
            "loss: 0.005412  [51200/70000]\n",
            "loss: 0.006252  [57600/70000]\n",
            "loss: 0.006494  [64000/70000]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.005319  [    0/70000]\n",
            "loss: 0.006891  [ 6400/70000]\n",
            "loss: 0.007108  [12800/70000]\n",
            "loss: 0.006960  [19200/70000]\n",
            "loss: 0.006807  [25600/70000]\n",
            "loss: 0.005944  [32000/70000]\n",
            "loss: 0.006405  [38400/70000]\n",
            "loss: 0.007888  [44800/70000]\n",
            "loss: 0.006721  [51200/70000]\n",
            "loss: 0.005759  [57600/70000]\n",
            "loss: 0.006179  [64000/70000]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.007188  [    0/70000]\n",
            "loss: 0.007122  [ 6400/70000]\n",
            "loss: 0.005287  [12800/70000]\n",
            "loss: 0.006139  [19200/70000]\n",
            "loss: 0.006532  [25600/70000]\n",
            "loss: 0.006371  [32000/70000]\n",
            "loss: 0.006877  [38400/70000]\n",
            "loss: 0.006143  [44800/70000]\n",
            "loss: 0.007181  [51200/70000]\n",
            "loss: 0.006267  [57600/70000]\n",
            "loss: 0.005104  [64000/70000]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.005783  [    0/70000]\n",
            "loss: 0.006528  [ 6400/70000]\n",
            "loss: 0.005885  [12800/70000]\n",
            "loss: 0.005988  [19200/70000]\n",
            "loss: 0.007404  [25600/70000]\n",
            "loss: 0.005672  [32000/70000]\n",
            "loss: 0.005538  [38400/70000]\n",
            "loss: 0.005825  [44800/70000]\n",
            "loss: 0.006329  [51200/70000]\n",
            "loss: 0.007687  [57600/70000]\n",
            "loss: 0.004099  [64000/70000]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXTpwTXuWG5x"
      },
      "outputs": [],
      "source": [
        "# https://www.google.com/search?q=pytorch+training+loops+online&rlz=1C1GCEB_enUS979US979&oq=pytorch+training+loops+online&aqs=chrome..69i57j33i299.949j0j7&sourceid=chrome&ie=UTF-8#fpstate=ive&vld=cid:86f4071d,vid:c36lUUr864M\n",
        "\n",
        "# https://pyimagesearch.com/2021/07/12/intro-to-pytorch-training-your-first-neural-network-using-pytorch/\n",
        "\n",
        "# https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYdpv-_QIrZj"
      },
      "source": [
        "## Validate the Model (3 points)\n",
        "\n",
        "Use the test dataset from the train-test split to make sure your model is not overfitting\n",
        "\n",
        "1. You can build a dataloader as you did before, this time with the test data.\n",
        "2. Build a validation loop, which you should use `with torch.no_grad()` to make sure you do not modify the gradients, or weights. This will fix your model. \n",
        "3. Instantiate the loss to be 0.\n",
        "4. Build a similar loop to grab the validation dataset. \n",
        "5. Compute the predictions with the model.\n",
        "6. Compute the loss using your loss criteria.\n",
        "7. Print the final loss determined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWZDUff9IrZj"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "# https://courses.coe.drexel.edu/MEM/MEMT680/Topic_10/6_autogradqs_tutorial.html?highlight=torch%20no_grad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code should go here\n",
        "def test_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    test_loop(loader_p_test, model, loss_fn, optimizer)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtWhVgGxVya_",
        "outputId": "46a87e7d-49d0-43f0-8f88-1e2cd6b9b928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.005573  [    0/30000]\n",
            "loss: 0.005347  [ 6400/30000]\n",
            "loss: 0.006257  [12800/30000]\n",
            "loss: 0.004829  [19200/30000]\n",
            "loss: 0.006260  [25600/30000]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.005391  [    0/30000]\n",
            "loss: 0.004513  [ 6400/30000]\n",
            "loss: 0.005964  [12800/30000]\n",
            "loss: 0.005585  [19200/30000]\n",
            "loss: 0.004781  [25600/30000]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.006058  [    0/30000]\n",
            "loss: 0.006891  [ 6400/30000]\n",
            "loss: 0.005179  [12800/30000]\n",
            "loss: 0.004359  [19200/30000]\n",
            "loss: 0.006680  [25600/30000]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.004959  [    0/30000]\n",
            "loss: 0.005233  [ 6400/30000]\n",
            "loss: 0.003994  [12800/30000]\n",
            "loss: 0.005127  [19200/30000]\n",
            "loss: 0.005712  [25600/30000]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.004768  [    0/30000]\n",
            "loss: 0.005449  [ 6400/30000]\n",
            "loss: 0.005018  [12800/30000]\n",
            "loss: 0.004683  [19200/30000]\n",
            "loss: 0.004621  [25600/30000]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.004726  [    0/30000]\n",
            "loss: 0.005674  [ 6400/30000]\n",
            "loss: 0.005217  [12800/30000]\n",
            "loss: 0.004894  [19200/30000]\n",
            "loss: 0.004727  [25600/30000]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.005545  [    0/30000]\n",
            "loss: 0.005381  [ 6400/30000]\n",
            "loss: 0.005640  [12800/30000]\n",
            "loss: 0.003932  [19200/30000]\n",
            "loss: 0.006220  [25600/30000]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.005161  [    0/30000]\n",
            "loss: 0.006325  [ 6400/30000]\n",
            "loss: 0.005958  [12800/30000]\n",
            "loss: 0.005239  [19200/30000]\n",
            "loss: 0.004326  [25600/30000]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.005363  [    0/30000]\n",
            "loss: 0.004600  [ 6400/30000]\n",
            "loss: 0.005925  [12800/30000]\n",
            "loss: 0.004973  [19200/30000]\n",
            "loss: 0.005096  [25600/30000]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.005248  [    0/30000]\n",
            "loss: 0.004722  [ 6400/30000]\n",
            "loss: 0.004115  [12800/30000]\n",
            "loss: 0.004846  [19200/30000]\n",
            "loss: 0.004399  [25600/30000]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.005028  [    0/30000]\n",
            "loss: 0.004880  [ 6400/30000]\n",
            "loss: 0.005060  [12800/30000]\n",
            "loss: 0.004846  [19200/30000]\n",
            "loss: 0.005658  [25600/30000]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.004830  [    0/30000]\n",
            "loss: 0.005829  [ 6400/30000]\n",
            "loss: 0.003923  [12800/30000]\n",
            "loss: 0.004256  [19200/30000]\n",
            "loss: 0.004805  [25600/30000]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.004383  [    0/30000]\n",
            "loss: 0.004182  [ 6400/30000]\n",
            "loss: 0.005009  [12800/30000]\n",
            "loss: 0.005207  [19200/30000]\n",
            "loss: 0.004039  [25600/30000]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.003852  [    0/30000]\n",
            "loss: 0.004097  [ 6400/30000]\n",
            "loss: 0.005093  [12800/30000]\n",
            "loss: 0.004335  [19200/30000]\n",
            "loss: 0.004338  [25600/30000]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.004943  [    0/30000]\n",
            "loss: 0.003943  [ 6400/30000]\n",
            "loss: 0.004632  [12800/30000]\n",
            "loss: 0.005062  [19200/30000]\n",
            "loss: 0.003978  [25600/30000]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.004743  [    0/30000]\n",
            "loss: 0.004090  [ 6400/30000]\n",
            "loss: 0.005129  [12800/30000]\n",
            "loss: 0.004687  [19200/30000]\n",
            "loss: 0.004802  [25600/30000]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.004840  [    0/30000]\n",
            "loss: 0.004074  [ 6400/30000]\n",
            "loss: 0.006802  [12800/30000]\n",
            "loss: 0.005156  [19200/30000]\n",
            "loss: 0.003569  [25600/30000]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.004227  [    0/30000]\n",
            "loss: 0.004439  [ 6400/30000]\n",
            "loss: 0.004121  [12800/30000]\n",
            "loss: 0.004286  [19200/30000]\n",
            "loss: 0.004643  [25600/30000]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.004356  [    0/30000]\n",
            "loss: 0.004720  [ 6400/30000]\n",
            "loss: 0.005280  [12800/30000]\n",
            "loss: 0.005086  [19200/30000]\n",
            "loss: 0.004620  [25600/30000]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.003755  [    0/30000]\n",
            "loss: 0.005262  [ 6400/30000]\n",
            "loss: 0.003994  [12800/30000]\n",
            "loss: 0.004758  [19200/30000]\n",
            "loss: 0.004554  [25600/30000]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crnGbbvTIrZj"
      },
      "source": [
        "<p style=\"color:blue\"> Question: Is your model overfitting or not? How do you know? (3 points) </p>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the loss of the training set is much smaller than the loss of the test set, it means the model overfitting and fitted perfectly on the training set and does not work properly on the test set."
      ],
      "metadata": {
        "id": "PEzAH9VdfwAV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBGMVLgOIrZj"
      },
      "source": [
        "Type your response here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4Y7KTcDIrZk"
      },
      "source": [
        "## Crack Your Code (3 points)\n",
        "\n",
        "1. You can build a dataloader as you did before, this time with the validation features to view your code.\n",
        "2. Build a loop, you should use `with torch.no_grad()` to make sure you do not modify the gradients or weights. This will fix your model. \n",
        "3. Compute the predictions of your model. \n",
        "    - Make sure you do all the same preprocess, the data has the same datatype, and is on the same device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsQTG8HCSdXh"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "validation_dataloader_y = DataLoader(scaled_validation_feat, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    with torch.no_grad():\n",
        "      for X in dataloader:\n",
        "        pred = model(X)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    validation_loop(validation_dataloader_y, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "iVWWRJReuG9F",
        "outputId": "a4c17c59-9f7f-4f17-f7bb-2c20254bb3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-6cf61131bfb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mvalidation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataloader_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-6cf61131bfb6>\u001b[0m in \u001b[0;36mvalidation_loop\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-260113448991>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsRmXbaUIrZk"
      },
      "source": [
        "## Reveal Your Code (3 points)\n",
        "\n",
        "Your code is an image. there are (65536, 3) predictions this corresponds to a (256,256,3) RGB image. \n",
        "1. Use the detach() method to remove the gradients from the tensor\n",
        "2. Transfer the tensor back to the 'cpu' if you had it on a GPU\n",
        "3. Reshape the image into a 256,256,3 array. \n",
        "4. Plot your successful result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUHBogFwIrZk"
      },
      "outputs": [],
      "source": [
        "# Your Code goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrvmUuB5TeLk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xqaRcl_Tmyg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DsRmXbaUIrZk"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "c475b5beda6d617ffb7b2fcf453fbe132321ffc1e1f96c06cf49356e1e7f42cb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}